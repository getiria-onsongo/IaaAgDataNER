# Move NER working space (repo containing this code)
cd IaaAgDataNER

# For some reason download spacy using conda is not working correctly.
# pip appears to work with no problems.
pip3 install -U pip setuptools wheel
pip3 install -U spacy

# Download language models
python3 -m spacy download en_core_web_sm
python3 -m spacy download en_core_web_md
python3 -m spacy download en_core_web_lg

# Install transformer package. It is sometimes using in training
pip3 install spacy-transformers

# Install scikit-learn
pip3 install -U scikit-learn
pip3 install -U PyPDF2


# Take as input a folder containing raw json files and convert them into
# jsonl format used by Spacy
path_to_src=/Users/gonsongo/Desktop/research/iaa/Projects/python/IaaAgDataNER/src/
cd /Users/gonsongo/Desktop/research/iaa/Projects/python/IaaAgDataNER
python3 src/json2SpacyJson.py Data ner_2021_08 en_core_web_lg --suffix '.json' --split True --test_size 0.1

# Create directory. Spacy program to convert jsonl to Spacy format needs an output directory
mkdir ner_2021_08

# Convert to spacy binary format
python3 -m spacy convert --converter json ner_2021_08_training_data.jsonl ner_2021_08
python3 -m spacy convert --converter json ner_2021_08_validate_data.jsonl ner_2021_08

# Create a config file to use for training
# --lang: Two-letter code of the language to use
# --pipeline: Comma-separated names of trainable pipeline components to include [default: tagger,parser,ner]
# --optimize: Whether to optimize for efficiency or accuracy
# --force: Overwrite output file if it exists
# train.cfg:
# python3 -m spacy init config --lang en  --optimize accuracy --force train.cfg

python3 -m spacy init config --lang en --pipeline ner  --optimize accuracy --force ner.cfg

# NOTE: If you just have ner in the pipeline as below, you will not get things such as POS which
# we need. Ensure tagger and parser are in the pipeline you are training, add the following lines
# to include other components in the pipeline. Another side note, "attribute_ruler" is the one
# that creates POS in SpaCY 3.
pipeline = ["tok2vec","tagger","parser","attribute_ruler","lemmatizer","ner"]

[components.tagger]
source = "en_core_web_lg"
replace_listeners = ["model.tok2vec"]

[components.parser]
source = "en_core_web_lg"
replace_listeners = ["model.tok2vec"]

[components.attribute_ruler]
source = "en_core_web_lg"
replace_listeners = ["model.tok2vec"]

[components.lemmatizer]
source = "en_core_web_lg"
replace_listeners = ["model.tok2vec"]

frozen_components = ["tagger","parser","attribute_ruler","lemmatizer"]

# Train a model
python3 -m spacy train ner.cfg --output ner_2021_08_model --paths.train ner_2021_08/ner_2021_08_training_data.spacy --paths.dev ner_2021_08/ner_2021_08_validate_data.spacy


# Start GUI and select "ner_2021_08_model/model-best" as the model
python3 src/CropNerGUI.py


# To remove an environment
conda remove --name ner_june_2021 --all -y

# Convert JSON to CSV
path_to_src=/Users/gonsongo/Desktop/research/iaa/Projects/python/IaaAgDataNER/src/
python3 $path_to_src/json2csv.py AnnotatedData BarCvDescLJ11.csv

# POSTGRESQL
# Login as default user
> psql postgres

# Create new user
> CREATE ROLE ner WITH LOGIN PASSWORD 'j***_1*';

> ALTER ROLE ner CREATEDB;

# To create a database run the command below ON THE COMMANDLINE (not psql). This creates the
# database ner
> createdb ner

# Log in
> psql -U ner -h localhost -d ner


\COPY raw_data FROM 'Bond-CL-Reprint.txt' DELIMITER E'\t';
\COPY raw_data FROM 'BoulderProfile.txt' DELIMITER E'\t';
\COPY raw_data FROM 'HS1296.txt' DELIMITER E'\t';
\COPY raw_data FROM 'Incline-AX.txt' DELIMITER E'\t';
\COPY raw_data FROM 'adirondack-blue-fact-sheet.txt' DELIMITER E'\t';
\COPY raw_data FROM 'clearwater-russet-fact-sheet.txt' DELIMITER E'\t';
\COPY raw_data FROM 'yukon-gold-potato-fact-sheet-3.txt' DELIMITER E'\t';
\COPY raw_data FROM 'yukon-gold-solanum-tuberosum.txt' DELIMITER E'\t';
\COPY raw_data FROM 'yukongold_characteristics.txt' DELIMITER E'\t';

DROP TABLE IF EXISTS crop_variety ;
CREATE TABLE crop_variety AS
SELECT DISTINCT variety_name, value as crop_name FROM raw_data
WHERE category = 'crop name';
ALTER TABLE crop_variety ADD PRIMARY KEY (variety_name);

DROP TABLE IF EXISTS annotation_source ;
CREATE TABLE annotation_source AS
SELECT DISTINCT date_time, file_name, variety_name, value as source FROM raw_data
WHERE category = 'source';
ALTER TABLE annotation_source ADD PRIMARY KEY (variety_name, date_time);
ALTER TABLE annotation_source ADD CONSTRAINT fk_annot_source_crop_var
FOREIGN KEY (variety_name) REFERENCES crop_variety (variety_name);

DROP TABLE IF EXISTS category;
CREATE TABLE category AS
SELECT DISTINCT category AS category_name FROM raw_data;
ALTER TABLE category ADD PRIMARY KEY (category_name);

DROP TABLE IF EXISTS trait;
CREATE TABLE trait AS
SELECT DISTINCT  variety_name, date_time, value AS trait_description, category AS category_name
FROM raw_data;
ALTER TABLE trait ADD CONSTRAINT fk_trait_annot_source
FOREIGN KEY (variety_name, date_time) REFERENCES annotation_source (variety_name, date_time);
ALTER TABLE trait ADD CONSTRAINT fk_trait_category
FOREIGN KEY (category_name) REFERENCES category (category_name);
ALTER TABLE trait ADD PRIMARY KEY (variety_name, trait_description, category_name, date_time);

-- ------------ HERE
SELECT DISTINCT trait_description
FROM
(SELECT * FROM trait WHERE category_name LIKE '%trait%') A
JOIN
(SELECT  variety_name, crop_name FROM crop_variety WHERE crop_name = 'potato' AND variety_name = 'clearwater russet') B
USING(variety_name);




SELECT DISTINCT date_time, variety_name, category AS category_name FROM raw_data order by variety_name,category;



SELECT DISTINCT * FROM raw_data WHERE category = 'source';

# Exit postgreSQL then create tables (relations)
> path_to_sql=/Users/gonsongo/Desktop/research/gems/IaaAgDataNER/src/CreateTables.sql
> psql -U ner -h localhost -d ner -f $path_to_sql

# Log into PostgreSQL and load raw data.
psql -h localhost -d ner
\COPY raw_data FROM '/Users/gonsongo/Desktop/BarCvDescLJ11/BarCvDescLJ11.csv' DELIMITER ',' CSV HEADER;

# Create CSV files from raw_data
\COPY (SELECT DISTINCT crop_name FROM raw_data) to 'crop.csv' CSV;
\COPY (SELECT DISTINCT doc_name, url FROM raw_data) to 'document.csv' CSV;
\COPY (SELECT DISTINCT cvar, crop_name FROM raw_data) to 'crop_variety.csv' CSV;
\COPY (SELECT DISTINCT id, chunk, doc_name, cvar FROM raw_data) to 'cvar_data_source.csv' CSV;
\COPY (SELECT DISTINCT id, label FROM raw_data) to 'ner_tag.csv' CSV;
\COPY (SELECT DISTINCT value, id, label FROM raw_data) to 'crop_attribute.csv' CSV;

# Load data to tables
\COPY crop FROM 'crop.csv' DELIMITER ',' QUOTE '"' CSV;
\COPY document FROM 'document.csv' DELIMITER ',' QUOTE '"' CSV;
\COPY crop_variety FROM 'crop_variety.csv' DELIMITER ',' QUOTE '"' CSV;
\COPY cvar_data_source FROM 'cvar_data_source.csv' DELIMITER ',' QUOTE '"' CSV;
\COPY ner_tag FROM 'ner_tag.csv' DELIMITER ',' QUOTE '"' CSV;
\COPY crop_attribute FROM 'crop_attribute.csv' DELIMITER ',' QUOTE '"' CSV;

# Create indexes to help views. If queries using views start slowing down, consider
# materialized views
CREATE INDEX crop_attribute_id_idx ON crop_attribute USING BTREE(id);

# Create view
CREATE VIEW crop_data AS
SELECT DISTINCT crop_name, cvar, label, value FROM
(SELECT crop_name, cvar, id FROM crop_variety JOIN cvar_data_source USING(cvar)) A
JOIN
crop_attribute B
USING(ID);

select value from crop_data where crop_name = 'barley' and cvar = 'strider' and label = 'TRAT';

# -------------- Setting up jupyter notebook
> conda activate spacyLLM

> conda install -c anaconda notebook

> jupyter notebook &


import os
import shutil
from IPython.display import IFrame
source = "/Users/gonsongo/Desktop/research/gems/IaaAgDataNER/Data/test/BoulderProfile.pdf"
destination = "./test.pdf"


status = shutil.copyfile(source, destination)


IFrame(destination, width=600, height=300)